---
title: 锁
date: 2019-04-28 21:30:32
tags:
---

1. 自旋锁(spinlock) do while 、忙等、（理解成死循环等锁 因此不适合较长时间的任务，等待的过程非常耗CPU）
2. 互斥锁(mutexlock) 休眠状态等锁
3. 读写锁(rwlock)：处于“写锁”时任何操作都要休眠等锁
4. 递归锁(recursivelock)：是互斥锁的一个特例 允许同一个线程在未释放拥有的锁时反复对该锁进行加锁操作
3. 死锁 一个资源被多次调用，而多次调用方都未能释放该资源就会造成一种互相等待的现象，若无外力作用，它们都将无法推进下去。此时称系统处于死 锁状态或系统产生了死锁。



1. @synchronized 关键字加锁
    用法简洁、可读性强：传入对象即可，没有显示的添加锁、释放锁代码
    ```objc
    @synchronized(obj){
        // do work 
    }
    ```
    杨肖玉的博客中翻译了国外大神的文章并做了详细的解释，对下面的问题有很详细的解读，博客地址：http://yulingtianxia.com/blog/2015/11/01/More-than-you-want-to-know-about-synchronized/
    
    1. 锁是如何传入@synchronized的对象关联上的?
    2. 如果传入@synchronized的对象在@synchronized的block里面被释放或者被赋值为nil会怎样?
    
    下面是阅读完博客后的笔记。

    首先 apple文档中有一段话：（地址：https://developer.apple.com/library/archive/documentation/Cocoa/Conceptual/Multithreading/ThreadSafety/ThreadSafety.html#//apple_ref/doc/uid/10000057i-CH8-SW3）
    As a precautionary measure, the @synchronized block implicitly adds an exception handler to the protected code. This handler automatically releases the mutex in the event that an exception is thrown. This means that in order to use the @synchronized directive, you must also enable Objective-C exception handling in your code. If you do not want the additional overhead caused by the implicit exception handler, you should consider using the lock classes.
    其中`the @synchronized block implicitly adds an exception handler to the protected code` 意思是@synchronized为代码块为隐式地添加了一个异常处理。

    `@synchronized` block 会变成 `objc_sync_enter` 和 `objc_sync_exit` 的成对儿调用
    可以理解成上面的代码转化成了下面这样：
    ```objc
    @synchronized(obj){
        // do work 
    }

        @try {
            objc_sync_enter(obj);
            // do work
        } @finally {
            objc_sync_exit(obj);    
        }

    ```
    ## 源码探究  最新源码地址：https://opensource.apple.com/source/objc4/objc4-750/runtime/objc-sync.mm.auto.html

    `<objc/objc-sync.h>`中：
    ```objc
    typedef struct alignas(CacheLineSize) SyncData {
        struct SyncData* nextData;
        DisguisedPtr<objc_object> object;
        int32_t threadCount;  // number of THREADS using this block
        recursive_mutex_t mutex;
    } SyncData;
    typedef struct {
        SyncData *data;
        unsigned int lockCount;  // number of times THIS THREAD locked this block
    } SyncCacheItem;
    typedef struct SyncCache {
        unsigned int allocated;
        unsigned int used;
        SyncCacheItem list[0];
    } SyncCache;

    /*
    Fast cache: two fixed pthread keys store a single SyncCacheItem. 
    This avoids malloc of the SyncCache for threads that only synchronize 
    a single object at a time.
    SYNC_DATA_DIRECT_KEY  == SyncCacheItem.data
    SYNC_COUNT_DIRECT_KEY == SyncCacheItem.lockCount
    */

    struct SyncList {
        SyncData *data;
        spinlock_t lock;

        constexpr SyncList() : data(nil), lock(fork_unsafe_lock) { }
    };
    // Use multiple parallel lists to decrease contention among unrelated objects.
    #define LOCK_FOR_OBJ(obj) sDataLists[obj].lock
    #define LIST_FOR_OBJ(obj) sDataLists[obj].data
    static StripedMap<SyncList> sDataLists;

    ```
    `SyncList`可以看成是一个链表（key是对象地址的hash值），`SyncData`是链表中的某个节点。
    `SyncData`包括了`object`（就是我们传入的对象）、`nextData`（链表中的下一个节点）、`recursive_mutex_t`类型（递归锁）的`mutex`（与之关联的一个互斥锁）、`threadCount`（被使用的线程的数量） 

    `objc_sync_enter`
    ```objc
    int objc_sync_enter(id obj)
    {
        int result = OBJC_SYNC_SUCCESS;

        if (obj) {
            SyncData* data = id2data(obj, ACQUIRE);
            assert(data);
            data->mutex.lock();
        } else {
            // @synchronized(nil) does nothing
            if (DebugNilSync) {
                _objc_inform("NIL SYNC DEBUG: @synchronized(nil); set a breakpoint on objc_sync_nil to debug");
            }
            objc_sync_nil();
        }

        return result;
    }
    ```
    1. 首先回答如果obj为nil的情况 ：`@synchronized(nil) does nothing` 
    `objc_sync_nil` 什么也不做
    2. obj不为空： 调用`id2data`取出obj对应的SyncData，判断之后进行加锁操作 
    `objc_sync_exit`
    ```objc
    int objc_sync_exit(id obj)
    {
        int result = OBJC_SYNC_SUCCESS;
        
        if (obj) {
            SyncData* data = id2data(obj, RELEASE); 
            if (!data) {
                result = OBJC_SYNC_NOT_OWNING_THREAD_ERROR;
            } else {
                bool okay = data->mutex.tryUnlock();
                if (!okay) {
                    result = OBJC_SYNC_NOT_OWNING_THREAD_ERROR;
                }
            }
        } else {
            // @synchronized(nil) does nothing
        }
        

        return result;
    }
    ```
    1. 惯例回答 如果代码执行完是，obj为nil： `@synchronized(nil) does nothing`
    2. obj不为空： 调用`id2data`取出obj对应的SyncData，判断之后进行解锁操作 
    那么`id2data`在传入了`obj` 加锁解锁时，函数内部具体做了什么呢？
    `id2data`代码比较长，为了方便阅读，直接将笔记写在里面

    ```objc
    static SyncData* id2data(id object, enum usage why)
    { 
        
        spinlock_t *lockp = &LOCK_FOR_OBJ(object);//lockp指向SyncList对象中的自旋锁
        SyncData **listp = &LIST_FOR_OBJ(object);//listp指向SyncList链表 
        SyncData* result = NULL;
    //对于同一个线程来说，有两种缓存方式：
        //第一种：快速缓存（fastCache），适用于一个线程一次只对一个对象加锁的情况，用宏SUPPORT_DIRECT_THREAD_KEYS来标识
        //这种情况意味着同一时间内，线程缓存中只有一个SyncCacheItem对象，键值SYNC_DATA_DIRECT_KEY和SYNC_COUNT_DIRECT_KEY分别对应SyncCacheItem结构体中的SyncData对象和lockCount.

    #if SUPPORT_DIRECT_THREAD_KEYS
        // Check per-thread single-entry fast cache for matching object 
        // 用于标识当前线程的是否已使用fastCache
        bool fastCacheOccupied = NO;
        SyncData *data = (SyncData *)tls_get_direct(SYNC_DATA_DIRECT_KEY);//获取syncdata
        if (data) {
            fastCacheOccupied = YES;
    //标识fastcache被使用

            if (data->object == object) {
    //判断fastcache中SyncData中的object与当前的对象是否一致
    // Found a match in fast cache.
                uintptr_t lockCount;

                result = data;
                lockCount = (uintptr_t)tls_get_direct(SYNC_COUNT_DIRECT_KEY);//获取当前线程中SyncData对象已经加锁的次数

                if (result->threadCount <= 0  ||  lockCount <= 0) {
                    _objc_fatal("id2data fastcache is buggy");//对象发生错误
                }
                switch(why) {//判断当前的操作是加锁还是解锁
                case ACQUIRE: {//加锁 然后更新
                    lockCount++;
                    tls_set_direct(SYNC_COUNT_DIRECT_KEY, (void*)lockCount);
                    break;
                }
                case RELEASE://解锁 
                    lockCount--;
                    tls_set_direct(SYNC_COUNT_DIRECT_KEY, (void*)lockCount);
                    if (lockCount == 0) {//如果lockCount为零 
                        // remove from fast cache
                        //将对应的SyncData对象从线程缓存中移除
                        tls_set_direct(SYNC_DATA_DIRECT_KEY, NULL);
                        // atomic because may collide with concurrent ACQUIRE
                        //原子操作 确保线程安全
                        OSAtomicDecrement32Barrier(&result->threadCount);
                        //threadCount是多个线程共享的变量，用于记录对一个对象加锁的线程个数，threadCount对应的SyncData对象除了线程缓存中持有之外，还存在于全局哈希表sDataLists中，sDataLists哈希表是多个线程共享的数据结构，因此存在多线程访问的可能，因此需要加锁；而lockCount则与线程一一对应且存储在线程的缓存区中，不存在多线性读写问题，因此不需要加锁
                        
                    }
                    break;
                case CHECK:
                    // do nothing
                    break;
                }

                return result;
            }
        }
    #endif

        // Check per-thread cache of already-owned locks for matching object
        // Check per-thread cache of already-owned locks for matching object
        //这是第二种缓存方式：使用SyncCache结构体来维护一个SyncCacheItem数组，这样一个线程就可以处理对多个同步对象。值得注意的是SyncCache与线程也是一对一的关系。

        SyncCache *cache = fetch_cache(NO);
        //获取当前线程缓存区中的SyncCache对象
        if (cache) {
            unsigned int i;
            //遍历SyncCache对象中的SyncCacheItem数组，匹配当前同步对象object
            for (i = 0; i < cache->used; i++) {
                SyncCacheItem *item = &cache->list[i];
                if (item->data->object != object) continue;

                // Found a match. 匹配到了
                result = item->data;
                if (result->threadCount <= 0  ||  item->lockCount <= 0) {
                    _objc_fatal("id2data cache is buggy");
                }
                    
                switch(why) { 
    //同上fast-cache一样
                case ACQUIRE:
                    item->lockCount++;
                    break;
                case RELEASE:
                    item->lockCount--;
                    if (item->lockCount == 0) {
                        // remove from per-thread cache
                        cache->list[i] = cache->list[--cache->used];
                        // atomic because may collide with concurrent ACQUIRE
                        OSAtomicDecrement32Barrier(&result->threadCount);
                    }
                    break;
                case CHECK:
                    // do nothing
                    break;
                }

                return result;
            }
        }

        // Thread cache didn't find anything.
        // Walk in-use list looking for matching object
        // Spinlock prevents multiple threads from creating multiple 
        // locks for the same new object.
        // We could keep the nodes in some hash table if we find that there are
        // more than 20 or so distinct locks active, but we don't do that now.
        
    //如果当前线程中的缓存中没有找到当前同步对象对应的SyncData对象，则在全局哈希表中查找
    //因为全局哈希表是多个线程共享的数据结构，因此需要进行加锁处理
        lockp->lock();

        {
            SyncData* p;
            SyncData* firstUnused = NULL;
    //遍历当前同步对象obejct在全局哈希表中的SyncData链表。这里之所以使用链表，是因为哈希表的hash算法不能确保hash的唯一性，存在多个对象对应一个hash值的情况。

            for (p = *listp; p != NULL; p = p->nextData) {
                if ( p->object == object ) {//匹配到了
                    result = p;
                    // atomic because may collide with concurrent RELEASE
                    OSAtomicIncrement32Barrier(&result->threadCount);//原子操作 
                    goto done;
                }
                if ( (firstUnused == NULL) && (p->threadCount == 0) )//标记空闲对象
                    firstUnused = p;
            }
        
            // no SyncData currently associated with object
    //由于此时同步对象object没有对应的SyncData对象，因此RELEASE与CHECK都属于无效操作
            if ( (why == RELEASE) || (why == CHECK) )
                goto done;
        
            // an unused one was found, use it
    //如果没有找到匹配的SyncData对象且存在空闲的SyncData对象，则直接使用，不需要创建新的SyncData，以提高效率。
            if ( firstUnused != NULL ) {
                result = firstUnused;
                result->object = (objc_object *)object;
                result->threadCount = 1;
                goto done;
            }
        }

        // Allocate a new SyncData and add to list.
        // XXX allocating memory with a global lock held is bad practice,
        // might be worth releasing the lock, allocating, and searching again.
        // But since we never free these guys we won't be stuck in allocation very often.
    //新建一个SyncData对象
    
        posix_memalign((void **)&result, alignof(SyncData), sizeof(SyncData));
        result->object = (objc_object *)object;
        result->threadCount = 1;
        new (&result->mutex) recursive_mutex_t(fork_unsafe_lock);
        result->nextData = *listp;
        *listp = result;
        
    done:
    //对全局哈希表的操作结束，解锁
        lockp->unlock();
        if (result) {
            // Only new ACQUIRE should get here.
            // All RELEASE and CHECK and recursive ACQUIRE are 
            // handled by the per-thread caches above.
            if (why == RELEASE) {
                // Probably some thread is incorrectly exiting 
                // while the object is held by another thread.
                return nil;
            }
            if (why != ACQUIRE) _objc_fatal("id2data is buggy");
            if (result->object != object) _objc_fatal("id2data is buggy");

    #if SUPPORT_DIRECT_THREAD_KEYS
            if (!fastCacheOccupied) {
                // Save in fast thread cache
                //直接缓存新建的SyncData对象
                tls_set_direct(SYNC_DATA_DIRECT_KEY, result);
                tls_set_direct(SYNC_COUNT_DIRECT_KEY, (void*)1);
            } else 
    #endif
            {
                // Save in thread cache
                if (!cache) cache = fetch_cache(YES);
                cache->list[cache->used].data = result;
                cache->list[cache->used].lockCount = 1;
                cache->used++;
            }
        }

        return result;
    }

    ```











2. dispatch_once 单例常用dispatch_once来保证某个单例
once.h 地址： https://opensource.apple.com/source/libdispatch/libdispatch-913.60.2/dispatch/once.h.auto.html



once.c 地址：https://opensource.apple.com/source/libdispatch/libdispatch-913.60.2/src/once.c.auto.html

2. NSLock


3. NSCondition


4. NSConditionLock
5. NSRecursiveLock
6. pthread_mutex
7. dispatch_semaphore 信号量
8. dispatch_async_barrier 读写锁
9. OSSpinLock
10. pthread_rwlock
11. POSIX Conditions
12. os_unfair_lock
